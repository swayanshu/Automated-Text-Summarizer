{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install sumy\n",
        "import nltk\n",
        "# nltk.download('punkt')\n",
        "from sumy.nlp.stemmers import Stemmer\n",
        "from sumy.utils import get_stop_words\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "\n",
        "def generate_summary(text):\n",
        "    # Initialize the parser, tokenizer, and summarizer\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    stemmer = Stemmer(\"english\")\n",
        "    summarizer = LsaSummarizer(stemmer)\n",
        "    # Set any language specific stop words\n",
        "    summarizer.stop_words = get_stop_words(\"english\")\n",
        "    # Generate a summary of the input text\n",
        "    summary = summarizer(parser.document, sentences_count=3)  # customize based on required sentence count\n",
        "    return summary\n",
        "\n",
        "# User Interaction\n",
        "while True:\n",
        "    user_input = input(\"Enter the text to summarize (type 'exit' to end):\\n\")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "    summary = generate_summary(user_input)\n",
        "    print(\"\\nOriginal Text:\")\n",
        "    print(user_input)\n",
        "    print(\"\\nGenerated Summary by model:\")\n",
        "    for sentence in summary:\n",
        "        print(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdKMhu86g9_z",
        "outputId": "fd564b3a-fd6b-41f2-db38-31b5077cacf6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the text to summarize (type 'exit' to end):\n",
            "Reinforcement rate of technics and appositeness towards the convenience of the human being is a perennial mechanism. Mathematics has always been in the root towards the implementation of an algorithm or analysis regarding statistics or language. Extracting more about the data and analyzing them to solve a particular problem is the reason behind any analysis. Scrutiny itself has the different number of outcome which can be predictive or descriptive. Now prediction is how far accurate is tested by using various techniques. The enhancement in problem-solving capability leads to come up with a new aptitude concerning machine learning algorithms. But before prediction of data set collection, exploration, feature extraction, model building, accuracy testing are primarily required to invent. So for explaining all these processes, concept learning is essential. In this paper different algorithms like SVM, Linear and Logistic Regression, Decision tree, and Random forest algorithms will be used to demonstrate the accuracy in titanic data from Kaggle Website with all the required steps by using Python language.\n",
            "\n",
            "Original Text:\n",
            "Reinforcement rate of technics and appositeness towards the convenience of the human being is a perennial mechanism. Mathematics has always been in the root towards the implementation of an algorithm or analysis regarding statistics or language. Extracting more about the data and analyzing them to solve a particular problem is the reason behind any analysis. Scrutiny itself has the different number of outcome which can be predictive or descriptive. Now prediction is how far accurate is tested by using various techniques. The enhancement in problem-solving capability leads to come up with a new aptitude concerning machine learning algorithms. But before prediction of data set collection, exploration, feature extraction, model building, accuracy testing are primarily required to invent. So for explaining all these processes, concept learning is essential. In this paper different algorithms like SVM, Linear and Logistic Regression, Decision tree, and Random forest algorithms will be used to demonstrate the accuracy in titanic data from Kaggle Website with all the required steps by using Python language.\n",
            "\n",
            "Generated Summary by model:\n",
            "The enhancement in problem-solving capability leads to come up with a new aptitude concerning machine learning algorithms.\n",
            "But before prediction of data set collection, exploration, feature extraction, model building, accuracy testing are primarily required to invent.\n",
            "In this paper different algorithms like SVM, Linear and Logistic Regression, Decision tree, and Random forest algorithms will be used to demonstrate the accuracy in titanic data from Kaggle Website with all the required steps by using Python language.\n",
            "Enter the text to summarize (type 'exit' to end):\n",
            "Here we have studied the basic about machine learning, linear regression, logistic regression, SVM, KNN, Decision tree and Random forest tree algorithm. We have executed the code by using python language and got the output successfully by using Confusion matrix, Precision-recall curve and ROC-AUC-Score. In the end, we have calculated Random forest, and decision tree model are giving a higher accuracy of 92.82 % of data by using modules from sci-kit learn. From ROC-AUC-Score we got the score as 0.9447 which is nearly giving cent percent correct prediction for the chosen model. The objective was for knowing all these five algorithms and code execution which is computed with accuracy. We have also performed confusion matrix, Area under curve score for result analysis and got the result by getting the Precision and Recall value. For the future work I will work on the significance of feature engineering while building a model using machine learning algorithms.\n",
            "\n",
            "Original Text:\n",
            "Here we have studied the basic about machine learning, linear regression, logistic regression, SVM, KNN, Decision tree and Random forest tree algorithm. We have executed the code by using python language and got the output successfully by using Confusion matrix, Precision-recall curve and ROC-AUC-Score. In the end, we have calculated Random forest, and decision tree model are giving a higher accuracy of 92.82 % of data by using modules from sci-kit learn. From ROC-AUC-Score we got the score as 0.9447 which is nearly giving cent percent correct prediction for the chosen model. The objective was for knowing all these five algorithms and code execution which is computed with accuracy. We have also performed confusion matrix, Area under curve score for result analysis and got the result by getting the Precision and Recall value. For the future work I will work on the significance of feature engineering while building a model using machine learning algorithms.\n",
            "\n",
            "Generated Summary by model:\n",
            "We have executed the code by using python language and got the output successfully by using Confusion matrix, Precision-recall curve and ROC-AUC-Score.\n",
            "In the end, we have calculated Random forest, and decision tree model are giving a higher accuracy of 92.82 % of data by using modules from sci-kit learn.\n",
            "From ROC-AUC-Score we got the score as 0.9447 which is nearly giving cent percent correct prediction for the chosen model.\n",
            "Enter the text to summarize (type 'exit' to end):\n",
            "The potential problems with clustering are:- 1. Distance measure identification: For numerical attributes distance measurement is difficult. In case of Murkowski distance where maximum distance calculation is found by numerical attribute. 2. Number of clusters: If number of class labels are unknown then number of cluster finding is not easy. 3. Class label lacking 4. Database structure: In real life databases are not having sufficient structured tuples which lead to missing of data. If data cannot be structured properly then clarification and completeness will not occur. 5. Different attributes in Database: Database may not contain distinctively numerical or categorized attributes. 1. High cost: Though cluster needs proper hardware and a design which is costly compared to non –clustered server management. 2. Clustering needs more h/w and severs to establish one, monitoring and maintenance is hard which increases the infrastructure.\n",
            "\n",
            "Original Text:\n",
            "The potential problems with clustering are:- 1. Distance measure identification: For numerical attributes distance measurement is difficult. In case of Murkowski distance where maximum distance calculation is found by numerical attribute. 2. Number of clusters: If number of class labels are unknown then number of cluster finding is not easy. 3. Class label lacking 4. Database structure: In real life databases are not having sufficient structured tuples which lead to missing of data. If data cannot be structured properly then clarification and completeness will not occur. 5. Different attributes in Database: Database may not contain distinctively numerical or categorized attributes. 1. High cost: Though cluster needs proper hardware and a design which is costly compared to non –clustered server management. 2. Clustering needs more h/w and severs to establish one, monitoring and maintenance is hard which increases the infrastructure.\n",
            "\n",
            "Generated Summary by model:\n",
            "Database structure: In real life databases are not having sufficient structured tuples which lead to missing of data.\n",
            "If data cannot be structured properly then clarification and completeness will not occur.\n",
            "Clustering needs more h/w and severs to establish one, monitoring and maintenance is hard which increases the infrastructure.\n",
            "Enter the text to summarize (type 'exit' to end):\n",
            "III . LIMITATIONS IN BIG DATA: Heterogeneity and Incompleteness: Though many types of data sets are combined together which leads to heterogeneity. Here working with heterogonous data leads to more challenging SECURITY AND PRIVACY CHALLENGES: This is the measure problem seen in case of big data. When personal information combined with such a large scale of data leads to complexity in their privacy of data. Quality of data decreases due to improper utilization. Fault Tolerance: Two methods which increase this tolerance in big data are 1. Divide whole computation being done by tasks and assign these tasks into different nodes for computation 2. One node is assigned the work of observing that these nodes are working properly. If something happens that particular task restarted.[1] But sometimes whole computation can’t be divided into independent tasks which lead to fault tolerance. Endogeneity: It refers to a feedback loop in a system. We can model and predict ants or algae far better than we can model and predict markets.Clustering is one of the solution in big data issues.\n",
            "\n",
            "Original Text:\n",
            "III . LIMITATIONS IN BIG DATA: Heterogeneity and Incompleteness: Though many types of data sets are combined together which leads to heterogeneity. Here working with heterogonous data leads to more challenging SECURITY AND PRIVACY CHALLENGES: This is the measure problem seen in case of big data. When personal information combined with such a large scale of data leads to complexity in their privacy of data. Quality of data decreases due to improper utilization. Fault Tolerance: Two methods which increase this tolerance in big data are 1. Divide whole computation being done by tasks and assign these tasks into different nodes for computation 2. One node is assigned the work of observing that these nodes are working properly. If something happens that particular task restarted.[1] But sometimes whole computation can’t be divided into independent tasks which lead to fault tolerance. Endogeneity: It refers to a feedback loop in a system. We can model and predict ants or algae far better than we can model and predict markets.Clustering is one of the solution in big data issues.\n",
            "\n",
            "Generated Summary by model:\n",
            "Here working with heterogonous data leads to more challenging SECURITY AND PRIVACY CHALLENGES: This is the measure problem seen in case of big data.\n",
            "Quality of data decreases due to improper utilization.\n",
            "[1] But sometimes whole computation can’t be divided into independent tasks which lead to fault tolerance.\n",
            "Enter the text to summarize (type 'exit' to end):\n",
            "exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GlnX55CuiKfq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}